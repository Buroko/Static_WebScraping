{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce04906-1607-4580-afcf-b326f1aeaf64",
   "metadata": {},
   "source": [
    "# BeatifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ec73-cea5-4075-a7fd-06f215c17a74",
   "metadata": {},
   "source": [
    "### BeautifulSoup is a Python library purposes to pull the data out of HTML and XML files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d761d533-6972-41d8-a197-ca45968c0d34",
   "metadata": {},
   "source": [
    "\n",
    "#### BeautifulSoup and Web Fetching:\n",
    "\n",
    "- BeautifulSoup is a library designed for parsing HTML and XML documents, not for fetching them from the web.\n",
    "- It doesn't include the functionality to download web pages.\n",
    "- That's why we need to use an additional library like requests to handle the HTTP requests to fetch the web page.\n",
    "\n",
    "#### Parsing HTML and XML:\n",
    "\n",
    "- Parsing HTML or XML content means analyzing a string of HTML or XML code to understand its structure and extract specific elements or data from it.\n",
    "- This process involves breaking down the document into a tree of elements and attributes.\n",
    "- The resulting tree can be easily navigated and manipulated to extract the desired information.\n",
    "\n",
    "\n",
    "<center>\n",
    "   <div align=\"center\">\n",
    "    <img src=\"https://th.bing.com/th/id/OIP.LA6AXbzvC0IQ_d2H8v3NCwAAAA?rs=1&pid=ImgDetMain\" alt=\"Description\" />\n",
    "    </div>\n",
    "</center>\n",
    "\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabe3b9-0ebd-4189-b892-9783f273e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you already have the HTML content (e.g., saved in a file or a string), you can use BeautifulSoup directly without requests\n",
    "#![image.png](attachment:d85bf1de-1ed7-4793-a3f2-c0d27bd87061.png)\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1- HTML content as a string\n",
    "html_content = '<html><head><title>Example</title></head><body></body></html>'\n",
    "\n",
    "## 2- Or open a local file \n",
    "## Open and read the HTML file\n",
    "# with open('example.html', 'r', encoding='utf-8') as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "title = soup.title.string\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814897a-66fb-4847-8b3f-27e7acb42bbe",
   "metadata": {},
   "source": [
    "# Requests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179be8d8-5edc-45ef-ae7e-31a786481115",
   "metadata": {},
   "source": [
    "### Requests is a Python library downloads content from the web."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367899fc-e04d-4e17-a42f-f7a4f80b99a1",
   "metadata": {},
   "source": [
    "- Is used to send HTTP requests to a specified URL and retrieve the content of the web page.\n",
    "- It handles the process of connecting to the server, sending the request, and receiving the response.\n",
    "- This includes retrieving the HTML content of the page, which can then be processed further.\n",
    "\n",
    "<center>\n",
    "   <div align=\"center\">\n",
    "    <img src=\"https://automation-help.com/wp-content/uploads/2021/01/get-requests.png.webp\" alt=\"Description\" />\n",
    "    </div>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a446adf-52d1-4865-a7c8-551f1d3249b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Make your URL here\n",
    "url = 'http://example.com'\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "print(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fe9b6-eb00-4454-b7fc-6a367b93a284",
   "metadata": {},
   "source": [
    "# BeautifulSoup & requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad5801-562e-4afe-93aa-3bf5b0875008",
   "metadata": {},
   "source": [
    "### We combine bouth of them to scrap static Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6773e-3f96-4e19-8009-0739188550ba",
   "metadata": {},
   "source": [
    "To download a web page and then parse its content.\n",
    "\n",
    "<center>\n",
    "   <div align=\"center\">\n",
    "    <img src=\"https://stackabuse.s3.amazonaws.com/media/parsing-html-with-beautifulsoup-in-python-1.jpg\" alt=\"Description\" />\n",
    "    </div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0894b30-62f2-46c4-ad1f-d4d2e55a61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrap_using_beauty():\n",
    "    # URL of the webpage you want to scrape\n",
    "    url = \"https://www.fedex.com/fedextrack/?trknbr=276581471468&trkqual=2460494000~276581471468~FX\"\n",
    "    \n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "        # Print the parsed HTML (or save it, analyze it, etc.)\n",
    "        print(soup.prettify())\n",
    "    else:\n",
    "        print(f'Failed to retrieve the webpage. Status code: {response.status_code}')\n",
    "\n",
    "scrap_using_beauty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a7286-e363-4a20-b5a7-56592ab372a9",
   "metadata": {},
   "source": [
    "# EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f710a3f-58f7-4351-a418-815714aac833",
   "metadata": {},
   "source": [
    "### for the hard workers  ðŸ¥´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993aaf35-d3f6-452f-afcd-533605ee9481",
   "metadata": {},
   "source": [
    "- firstfull be sure that the page allow the scraping, by : https//site.com/*robots.txt*\n",
    "- robots.txt : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
